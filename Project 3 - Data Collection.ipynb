{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== harrypotter.csv =====\n",
      "Unique Posts: 26/1000 (Sleep: 5 s)\n",
      "Unique Posts: 51/1000 (Sleep: 5 s)\n",
      "Unique Posts: 76/1000 (Sleep: 3 s)\n",
      "Unique Posts: 101/1000 (Sleep: 3 s)\n",
      "Unique Posts: 126/1000 (Sleep: 5 s)\n",
      "Unique Posts: 151/1000 (Sleep: 5 s)\n",
      "Unique Posts: 176/1000 (Sleep: 3 s)\n",
      "Unique Posts: 201/1000 (Sleep: 6 s)\n",
      "Unique Posts: 226/1000 (Sleep: 3 s)\n",
      "Unique Posts: 251/1000 (Sleep: 4 s)\n",
      "Unique Posts: 276/1000 (Sleep: 3 s)\n",
      "Unique Posts: 301/1000 (Sleep: 6 s)\n",
      "Unique Posts: 326/1000 (Sleep: 3 s)\n",
      "Unique Posts: 351/1000 (Sleep: 4 s)\n",
      "Unique Posts: 376/1000 (Sleep: 5 s)\n",
      "Unique Posts: 401/1000 (Sleep: 6 s)\n",
      "Unique Posts: 426/1000 (Sleep: 4 s)\n",
      "Unique Posts: 451/1000 (Sleep: 3 s)\n",
      "Unique Posts: 476/1000 (Sleep: 6 s)\n",
      "Unique Posts: 501/1000 (Sleep: 5 s)\n",
      "Unique Posts: 526/1000 (Sleep: 6 s)\n",
      "Unique Posts: 551/1000 (Sleep: 6 s)\n",
      "Unique Posts: 576/1000 (Sleep: 3 s)\n",
      "Unique Posts: 601/1000 (Sleep: 6 s)\n",
      "Unique Posts: 626/1000 (Sleep: 4 s)\n",
      "Unique Posts: 651/1000 (Sleep: 3 s)\n",
      "Unique Posts: 676/1000 (Sleep: 4 s)\n",
      "Unique Posts: 701/1000 (Sleep: 3 s)\n",
      "Unique Posts: 726/1000 (Sleep: 5 s)\n",
      "Unique Posts: 751/1000 (Sleep: 4 s)\n",
      "Unique Posts: 776/1000 (Sleep: 6 s)\n",
      "Unique Posts: 801/1000 (Sleep: 5 s)\n",
      "Unique Posts: 826/1000 (Sleep: 6 s)\n",
      "Unique Posts: 851/1000 (Sleep: 4 s)\n",
      "Unique Posts: 876/1000 (Sleep: 3 s)\n",
      "Unique Posts: 901/1000 (Sleep: 4 s)\n",
      "Unique Posts: 926/1000 (Sleep: 5 s)\n",
      "Unique Posts: 951/1000 (Sleep: 6 s)\n",
      "Unique Posts: 976/1000 (Sleep: 3 s)\n",
      "Unique Posts: 983/1000 (Sleep: 5 s)\n",
      "Extra sleep\n",
      "Unique Posts: 983/1000 (Sleep: 6 s)\n",
      "Unique Posts: 984/1000 (Sleep: 5 s)\n",
      "Extra sleep\n",
      "Unique Posts: 984/1000 (Sleep: 4 s)\n",
      "Extra sleep\n",
      "Unique Posts: 984/1000 (Sleep: 4 s)\n",
      "Extra sleep\n",
      "Unique Posts: 984/1000 (Sleep: 5 s)\n",
      "Extra sleep\n",
      "No additional unique posts for the subreddit!\n",
      "===== gameofthrones.csv =====\n",
      "Unique Posts: 25/1000 (Sleep: 6 s)\n",
      "Unique Posts: 50/1000 (Sleep: 3 s)\n",
      "Unique Posts: 75/1000 (Sleep: 5 s)\n",
      "Unique Posts: 100/1000 (Sleep: 3 s)\n",
      "Unique Posts: 125/1000 (Sleep: 6 s)\n",
      "Unique Posts: 150/1000 (Sleep: 5 s)\n",
      "Unique Posts: 175/1000 (Sleep: 6 s)\n",
      "Unique Posts: 200/1000 (Sleep: 6 s)\n",
      "Unique Posts: 225/1000 (Sleep: 6 s)\n",
      "Unique Posts: 250/1000 (Sleep: 6 s)\n",
      "Unique Posts: 275/1000 (Sleep: 4 s)\n",
      "Unique Posts: 300/1000 (Sleep: 3 s)\n",
      "Unique Posts: 325/1000 (Sleep: 4 s)\n",
      "Unique Posts: 350/1000 (Sleep: 6 s)\n",
      "Unique Posts: 375/1000 (Sleep: 3 s)\n",
      "Unique Posts: 400/1000 (Sleep: 3 s)\n",
      "Unique Posts: 425/1000 (Sleep: 4 s)\n",
      "Unique Posts: 450/1000 (Sleep: 4 s)\n",
      "Unique Posts: 475/1000 (Sleep: 5 s)\n",
      "Unique Posts: 500/1000 (Sleep: 4 s)\n",
      "Unique Posts: 525/1000 (Sleep: 6 s)\n",
      "Unique Posts: 548/1000 (Sleep: 5 s)\n",
      "Extra sleep\n",
      "Unique Posts: 548/1000 (Sleep: 5 s)\n",
      "Extra sleep\n",
      "Unique Posts: 548/1000 (Sleep: 6 s)\n",
      "Extra sleep\n",
      "Unique Posts: 548/1000 (Sleep: 4 s)\n",
      "Extra sleep\n",
      "Unique Posts: 548/1000 (Sleep: 3 s)\n",
      "Extra sleep\n",
      "No additional unique posts for the subreddit!\n",
      "===== lotr.csv =====\n",
      "Unique Posts: 26/1000 (Sleep: 3 s)\n",
      "Unique Posts: 51/1000 (Sleep: 4 s)\n",
      "Unique Posts: 76/1000 (Sleep: 3 s)\n",
      "Unique Posts: 101/1000 (Sleep: 6 s)\n",
      "Unique Posts: 126/1000 (Sleep: 3 s)\n",
      "Unique Posts: 151/1000 (Sleep: 6 s)\n",
      "Unique Posts: 176/1000 (Sleep: 3 s)\n",
      "Unique Posts: 201/1000 (Sleep: 5 s)\n",
      "Unique Posts: 226/1000 (Sleep: 5 s)\n",
      "Unique Posts: 251/1000 (Sleep: 6 s)\n",
      "Unique Posts: 276/1000 (Sleep: 4 s)\n",
      "Unique Posts: 301/1000 (Sleep: 6 s)\n",
      "Unique Posts: 326/1000 (Sleep: 3 s)\n",
      "Unique Posts: 351/1000 (Sleep: 4 s)\n",
      "Unique Posts: 376/1000 (Sleep: 5 s)\n",
      "Unique Posts: 401/1000 (Sleep: 4 s)\n",
      "Unique Posts: 426/1000 (Sleep: 3 s)\n",
      "Unique Posts: 451/1000 (Sleep: 6 s)\n",
      "Unique Posts: 476/1000 (Sleep: 6 s)\n",
      "Unique Posts: 501/1000 (Sleep: 6 s)\n",
      "Unique Posts: 526/1000 (Sleep: 3 s)\n",
      "Unique Posts: 551/1000 (Sleep: 6 s)\n",
      "Unique Posts: 576/1000 (Sleep: 5 s)\n",
      "Unique Posts: 601/1000 (Sleep: 3 s)\n",
      "Unique Posts: 626/1000 (Sleep: 5 s)\n",
      "Unique Posts: 651/1000 (Sleep: 4 s)\n",
      "Unique Posts: 676/1000 (Sleep: 4 s)\n",
      "Unique Posts: 701/1000 (Sleep: 3 s)\n",
      "Unique Posts: 726/1000 (Sleep: 5 s)\n",
      "Unique Posts: 739/1000 (Sleep: 6 s)\n",
      "Extra sleep\n",
      "Unique Posts: 739/1000 (Sleep: 4 s)\n",
      "Extra sleep\n",
      "Unique Posts: 739/1000 (Sleep: 6 s)\n",
      "Extra sleep\n",
      "Unique Posts: 739/1000 (Sleep: 4 s)\n",
      "Extra sleep\n",
      "Unique Posts: 739/1000 (Sleep: 3 s)\n",
      "Extra sleep\n",
      "No additional unique posts for the subreddit!\n",
      "COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "#VERSION 2 Getting the dataset from Reddit API until it reaches 1000 unique posts or when no more newer posts are received\n",
    "\n",
    "subreddits = ['harrypotter','gameofthrones','lotr']\n",
    "\n",
    "#urls  = [f'https://www.reddit.com/r/{subreddits[0]}.json',f'https://www.reddit.com/r/{subreddits[1]}.json']\n",
    "\n",
    "for idx, subreddit in enumerate(subreddits):\n",
    "    posts = []\n",
    "    csv_created = False\n",
    "    after = None\n",
    "    unique_posts = 0\n",
    "    url = f'https://www.reddit.com/r/{subreddits[idx]}.json'\n",
    "    filename = f'{subreddits[idx]}.csv'\n",
    "    repeat_counter = 0 \n",
    "    \n",
    "    print(f\"===== {filename} =====\")\n",
    "    while unique_posts < 1000:\n",
    "        last_unique_posts = unique_posts\n",
    "        if after == None:\n",
    "            current_url = url\n",
    "        else:\n",
    "            current_url = url + '?after=' + after\n",
    "        #print(current_url)\n",
    "        res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "        if res.status_code != 200:\n",
    "            print('Status error', res.status_code)\n",
    "            break\n",
    "        \n",
    "\n",
    "        current_dict = res.json()\n",
    "        current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "        posts.extend(current_posts)\n",
    "        after = current_dict['data']['after']\n",
    "\n",
    "        if csv_created:\n",
    "            prev_posts = pd.read_csv(filename)\n",
    "            current_df = pd.DataFrame(current_posts)\n",
    "            combined = (prev_posts.append(current_df))\n",
    "            combined.to_csv(filename, index = False)\n",
    "            unique_posts = combined['id'].unique().shape[0]\n",
    "        else:\n",
    "            csv_created = True\n",
    "            new_df = pd.DataFrame(posts)\n",
    "            new_df.to_csv(filename, index = False)\n",
    "            unique_posts = new_df['id'].unique().shape[0]\n",
    "            \n",
    "        if unique_posts == last_unique_posts:\n",
    "            sleep_duration = random.randint(10,60)\n",
    "            print(f'Extra sleep ({sleep_duration}s)')\n",
    "            time.sleep(sleep_duration)\n",
    "            repeat_counter += 1\n",
    "            \n",
    "        if repeat_counter == 5:\n",
    "            print('No additional unique posts for the subreddit!')\n",
    "            break\n",
    "\n",
    "        # generate a random sleep duration to look more 'natural'\n",
    "        sleep_duration = random.randint(3,6)\n",
    "        #print(f'Sleep Time: {sleep_duration}')\n",
    "        print(f'Unique Posts: {unique_posts}/1000 (Sleep: {sleep_duration} s)')\n",
    "        time.sleep(sleep_duration)\n",
    "print(\"COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
